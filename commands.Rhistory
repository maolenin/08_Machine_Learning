library(caret)
install.packages(caret)
install.packages("caret")
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
training <- spam[inTrain]
training <- spam[inTrain,]
testing <- spam[-inTrain,]
set.seed(32343)
modelFit <- train(type ~ ., data = training, method = "glm")
modelFit <- train(type ~ ., data = training, method = "glm")
library(e1071)
install.packages(e1071)
install.packages("e1071")
library(e1071)
modelFit <- train(type ~ ., data = training, method = "glm")
modelFit <- train(type ~ ., data = training, method = "glm")
modelFit$finalModel
predictions <- predict(modelFit, newData = testing)
predictions
confusionMatrix(predictions, testing$type)
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y = spam$type, p = .75, list = FALSE)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
dim(training)
set.seed(32323)
folds <- createFolds(y = spam$type, k = 10, list = TRUE, returnTrain = TRUE)
sapply(folds, length)
folds[[1]][1:10]
modelFit <- train(type ~ ., data = training, method = "glm")
library(ISLR)
install.packages("ISLR")
.libPaths()
myPaths <- .libPaths()
myPaths <- c(myPaths[2], myPaths[1])
.libPaths(myPaths)
.libPaths()
.libPaths()
myPaths <- .libPaths()
myPaths
myPaths <- c(myPaths[2], myPaths[1])
.libPaths(myPaths)
.libPaths()
library(ISLR)
library(caret)
library(lattice)
library(ggplot2)
data("Wage")
inTrain <- createDataPartition(y = Wage$wage, p = .7, list = FALSE)
training <- Wage[inTrain, ]; testing <- Wage[-inTrain]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass, data = training)
head(predict(dummies, newdata = training))
nsv <- nearZeroVar(training, saveMetrics = TRUE)
nsv
library(splines)
bsBasis <- bs(training$age)
bsBasis <- bs(training$age, df = 3)
bsBasis
lm1 <- lm(wage ~ bsBasis, data = training)
plot(training$age)
plot(training$age, training$wage, pch = 19, cex = 0.5)
points(training$age, predict(lm1, newdata = training), col = "red", pch = 19, cex = .5)
points(training$age, predict(lm1, newdata = training), col = "red", pch = 19, cex = .5)
M <- abs(cor(training[, -58]))
head(training)
dim(training)
data(spam)
data("spam")
library(kernlab)
data("spam")
inTrain <- spam[inTrain, ]
testing <- spam[-inTrain, ]
inTrain <- createDataPartition(y = spam$type, p = .75, llist = FALSE)
inTrain <- createDataPartition(y = spam$type, p = .75, list = FALSE)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
M <- abs(cor(training[, -58]))
diag(M) <- 0
which(M > 0.8, arr.ind = T)
names(spam)[c(34, 32)]
plot(spam[, 34], spam[, 32])
plot(spam[, 34], spam[, 40])
plot(spam[, 34], spam[, 32])
plot(spam[, 34], spam[, 40])
plot(spam[, 34], spam[, 32])
preproc <- preProcess(log10(spam[, -58] + 1), method = "pca", pcaComp = 2)
spamPC <- predict(preproc, log10(spam[, -58] + 1))
plot(spamPC[, 1], spamPC[, 2], col = typeColor)
typeColor <- ((spam$type == "spam") * 1 + 1 )
plot(spamPC[, 1], spamPC[, 2], col = typeColor)
trainPC <- predict(preproc, log10(spam[, -58] + 1))
modelFit <- train(training$type ~ ., method = "glm", data = trainPC)
trainPC <- predict(preproc, log10(training[, -58] + 1))
modelFit <- train(training$type ~ ., method = "glm", data = trainPC)
library(caret)
data("faithful")
set.seed(333)
inTrain <- createDataPartition(y = faithful$waiting, p = 0.5, list = FALSE)
trainFaith <- faithful[inTrain, ]; testFaith <- faithful[-inTrain, ]
head(trainFaith)
plot(trainFaith$waiting, trainFaith$eruptions, pch = 19, col = "blue", xlab = "Waiting", ylab = "Duration")
lm1 <- lm(eruptions ~ waiting, data = trainFaith)
summary(lm1)
plot(trainFaith$waiting, trainFaith$eruptions, pch = 19, col = "blue", xlab = "Waiting", ylab = "Duration")
lines(trainFaith$waiting, lm1$fitted, lwd = 3)
library(ISLR)
library(ggplot2)
library8caret
library(caret)
data(Wage)
Wage <- subset(Wage, select = c(logwage))
summary(Wage)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
dim(training})
dim(training)
dim(testing)
featurePlot(x = training[, c("age", "education", "jobclass")], y = training$wage, plot = "pairs")
qplot(age, wage, colour = jobclass, data = training)
qplot(age, wage, colour = education, data = training)
modFit <- train(wage ~ age + jobclass + education, method = "lm", data = training)
finMod <- modFit$finalModel
print(finMod)
plot(finMod, 1, pch = 19, cex = .5, col = "gray")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
str(AlzhermerDisease)
dat(AlzheimerDisease)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data("AlzheimerDisease")
AlzheimerDisease
library(AppliedPredictiveModeling)
data("AlzheimerDisease")
data("concrete")
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(concrete)
plot(CompressiveStrength ~ ., col = Age, data = cement)
plot(CompressiveStrength ~ ., col = Age, data = concrete)
?cut2
??cut2
library(Hmisc)
featurePlot(x = training[, 1:8], y = training$CompressiveStrength, plot = "pairs")
ggplot(compressiveStrength ~ ., data = concrete) + geom_point(color = concrete[, -9])
ggplot(data = concrete, aes = names(concrete[1:8])) + geom_point(color = concrete[, -9])
ggplot(data = concrete, aes(y = CompressiveStrength)) + geom_point(aes(x = names(concrete[1:8])))
ggplot(concrete, aes(y = CompressiveStrength)) + geom_point(aes(x = names(concrete[1:8])))
names(concrete[, 1:8])
ggplot(concrete, aes(y = CompressiveStrength)) + geom_point(aes(x = names(concrete[, 1:8])))
class(ames(concrete[, 1:8]))
class(names(concrete[, 1:8]))
ggplot(concrete, aes(y = CompressiveStrength)) + geom_point(aes(x = Cement))
g <- ggplot(concrete, aes(y = CompressiveStrength)) + geom_point(aes(x = Cement))
g
g + geom_point(aes(x = Water), color = "red")
g + geom_point(aes(x = BlastFurnaceSlag), color = "blue")
source('D:/Cursos/Coursera/Data Science/08_Machine_Learning/plots.R')
g
g <- ggplot(concrete, aes(y = CompressiveStrength))
g + geom_point(aes(x = Cement), color = "red")
g + geom_point(aes(x = BlastFurnaceSlag), color = "blue")
g + geom_point(aes(x = FlyAsh), color = "cyan")
g + geom_point(aes(x = Water), color = "yellow")
g + geom_point(aes(x = Superplasticizer), color = "green")
g + geom_point(aes(x = CoarseAggregate), color = "purple")
g + geom_point(aes(x = FineAggregate), color = "black")
g + geom_point(aes(x = Age), color = "pink")
g
source('D:/Cursos/Coursera/Data Science/08_Machine_Learning/plots.R')
source('D:/Cursos/Coursera/Data Science/08_Machine_Learning/plots.R')
g <- ggplot(concrete, aes(y = CompressiveStrength))
g + geom_point(aes(x = Cement), color = "red")
source('D:/Cursos/Coursera/Data Science/08_Machine_Learning/plots.R')
source('D:/Cursos/Coursera/Data Science/08_Machine_Learning/plots.R')
source('D:/Cursos/Coursera/Data Science/08_Machine_Learning/plots.R')
source('D:/Cursos/Coursera/Data Science/08_Machine_Learning/plots.R')
source('D:/Cursos/Coursera/Data Science/08_Machine_Learning/plots.R')
g <- ggplot(concrete, aes(y = CompressiveStrength))
g <- g + geom_point(aes(x = Cement), color = "red")
g
g <- ggplot(concrete, aes(y = CompressiveStrength))
g <- g + geom_point(aes(x = Cement), color = "red")
g <- g + geom_point(aes(x = BlastFurnaceSlag), color = "blue")
g
g <- ggplot(concrete, aes(y = CompressiveStrength))
g <- g + geom_point(aes(x = Cement), color = "red")
g <- g + geom_point(aes(x = BlastFurnaceSlag), color = "blue")
g <- g + geom_point(aes(x = FlyAsh), color = "cyan")
g <- g + geom_point(aes(x = Water), color = "yellow")
g <- g + geom_point(aes(x = Superplasticizer), color = "green")
g <- g + geom_point(aes(x = CoarseAggregate), color = "purple")
g <- g + geom_point(aes(x = FineAggregate), color = "black")
g <- g + geom_point(aes(x = Age), color = "pink")
g
str(concrete)
conccut <- cut2(concrete, 9)
index <. seq_along(1:nrow(training))
index <- seq_along(1:nrow(training))
ggplot(concrete, aes(index, CompressiveStrength)) + geom_point()
ggplot(training, aes(index, CompressiveStrength)) + geom_point()
head(index)
tail(index)
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point()
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
featurePlot(x = training[, 1:8], y = training$CompressiveStrength, plot = "pairs")
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point()
index <- seq_along(1:nrow(training))
head(indes), tail(index)
head(indes); tail(index)
head(index); tail(index)
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point() + theme_bw()
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(color = agexact.fit()) + theme_bw()
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(color = age + theme_bw()
)
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(color = age) + theme_bw()
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(color = Age) + theme_bw()
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(color = aes(Age)) + theme_bw()
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(color = Age) + theme_bw()
ggplot(training, aes(x = index, y = CompressiveStrength), color = Age) + geom_point() + theme_bw()
ggplot(training, aes(x = index, y = CompressiveStrength), color = Cement) + geom_point() + theme_bw()
ggplot(training, aes(x = index, y = CompressiveStrength), color = aes(Cement)) + geom_point() + theme_bw()
ggplot(training, aes(x = index, y = CompressiveStrength), color = aes(Cement)) + geom_point()
ggplot(training, aes(x = index, y = CompressiveStrength), color = aes(Cement)) + geom_point(color = "red")
ggplot(training, aes(x = index, y = CompressiveStrength), color = aes(Cement)) + geom_point(color = aes(Cement))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(color = aes(Cement))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(color = Cement)
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(color = "Cement")
ggplot(training, aes(x = index, y = CompressiveStrength), color = "Cement") + geom_point()
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(aes(color = Cement))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(aes(color = Flyash))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(aes(color = FlyAsh))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(aes(color = Cement))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(aes(color = BlastFurnaceSlag))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(aes(color = Water))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_point(aes(color = Age))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_bar(aes(color = Age))
ggplot(training, aes(x = index, y = CompressiveStrength)) + geom_bar()
ggplot(training, aes(CompressiveStrength)) + geom_bar()
ggplot(training, aes(CompressiveStrength)) + geom_histogram()
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(mixtures)
head(concrete)
str(training)
ggplot(training, aes(Superplasticizer)) + geom_histogram()
summary(training$Superplasticizer)
summary(concrete$Superplasticizer)
log10(0)
table(training[training$Superplasticizer == 0])
table(training[training$Superplasticizer == 0, 5])
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433); data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
names(training)
names(training["IL",])
names(training["^IL",])
names(training) = "^IL"
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
name <- names(training)
name == "^IL"
names
name
sort(name)
name[name == "^IL", ]
name[name == "^IL"]
name == "^IL"
str(name)
gsub(name = "^IL")
gsub(pattern = "^IL", name)
sub(pattern = "^IL", name)
grep(pattern = "^IL", name)
index <- grep(pattern = "^IL", name)
iindex
index
name[index]
grepl(pattern = "^IL", name)
grepl(pattern = "^IL", name, VALUE = TRUE)
grepl(pattern = "^IL", name, value = TRUE)
grep(pattern = "^IL", name, value = TRUE)
str(AlzheimerDisease)
str(adData)
dim(adData)
source('D:/Cursos/Coursera/Data Science/08_Machine_Learning/plots.R')
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
dim(adData)
adData = adData[, grep(pattern = "^IL", names(adData), value = TRUE)]
dim(adData)
names(adData)
adData = data.frame(diagnosis,predictors)
adData = adData[, c(diagnosis, grep(pattern = "^IL", names(adData), value = TRUE))]
adData = data.frame(diagnosis,predictors)
adData = adData[, c("diagnosis", grep(pattern = "^IL", names(adData), value = TRUE))]
names(adData)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(testing)
M <- abs(cor(training[, -1]))
diag(M) <- 0
which(M > 0.9, arr.ind = T)
which(M > 0.8, arr.ind = T)
which(M > 0.5, arr.ind = T)
which(M > 0.6, arr.ind = T)
which(M > 0.7, arr.ind = T)
train(diagnosis ~ ., data = training, preProcess = c("center", "scale"), method = "glm")
summary(testing)
name
preProc <- preProcess(training[, -1], method = "pca", tresh = 0.9)
preProc$rotation
?createDataPartition
confusionMatrix()
$confusionMatrix
?confusionMatrix
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
# Adding this line in order to subset the variables
adData = adData[, c("diagnosis", grep(pattern = "^IL", names(adData), value = TRUE))]
# adData = adData[, grep(pattern = "^IL", names(adData), value = TRUE)]
# Continue
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain, ]
testing = adData[-inTrain, ]
str(training[, -1])
preProc <- preProcess(training[, -1], method = "pca", tresh = 0.8)
print(preProc)
transformed <- predict(preProc, training)
summary(transformed)
?preProcess
?train
?train
savehistory("D:/Cursos/Coursera/Data Science/08_Machine_Learning/commands.Rhistory")
